{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_ml_40.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VigneshwaraChinnadurai/ML-Learning/blob/master/Session_40_Convolutional_Neural_Networking/CNN_ml_40.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oji4-mmGrGHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 1 - Building the CNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "# To initialize neural network\n",
        "from keras.layers import Convolution2D\n",
        "# To make convolutional layers. 2D for images and 3D for videos.\n",
        "from keras.layers import MaxPooling2D\n",
        "# To make pooling layers. 2D for images and 3D for videos.\n",
        "from keras.layers import Flatten\n",
        "# For flattining process.\n",
        "from keras.layers import Dense\n",
        "# To connect fully connected layers to artificial neural network model.\n",
        "# Using tensorflow package in backend inorder to make computations faster(Using GPU)."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfEJVqJkrK0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "# Deep learning model can be made deeper and deeper to increase accuracy by increasing the hidden layers\n",
        "# That is increasing the convolution layer."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj3JdCBWrMy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1 - Convolution\n",
        "classifier.add(Convolution2D(32, 3, 3, input_shape = (128, 128, 3), activation = 'relu'))\n",
        "# 32 feature detectors of 3x3 matrix to compare with input image to make convolution matrix.\n",
        "# Border_mode is to take care of borders in image.\n",
        "# Input_shape is the shape of the input image. This specific image shape is got by image pre-processing.\n",
        "# Run input image of size 128 and 256 only in gpu enabled machines.\n",
        "# As we are using tensorflow package, not theano package (3,128,128), input image is given as 128,128,3.\n",
        "# When we make convolutional matrix, we may get negative values. Inorder to avoid negative values, \n",
        "# using rectifier activation function. And to have some non-linearity."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ZDQgyVrPTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# There are many types of pooling and the one we use is max pooling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kodRjVQUrSpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding a second convolutional layer\n",
        "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQNvcKUrVAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTZxvfctrXBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
        "# Output_dim should not be too low, as it makes model useless , and too high, as it makes the model to computational.\n",
        "# Its good practice to take in power of 2 (Numbers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXDfh25srZYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H20Xg6yJrcCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "# If we have more than 2 output (such as caterorical), then we need to give categorical cross entropy\n",
        "# As here output is 0 or 1, dog or cat, we use binary cross entropy."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk0vW3_QrePw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "# In fact, Image Pre Processing\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Image augumentation is a technique which yields better results with lesser no of input images.\n",
        "# The trick used is it uses same image in multiple angles and formats to better fit the model.\n",
        "# This is flow from directory method.\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "# Rescale part is similar to feature scaling in data preprocessing part.\n",
        "# Rescale is given as 1./255 to change the values between 0 and 1.\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "# to align, select the code and press alt+shift\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "# First inside single quotes is the directory where we kept the images.\n",
        "# No need to give the full path as we kept the images in working directory.\n",
        "# Target size is the expected o/p size of images after pre-processing (as input given is 128,128 in convolution2d)\n",
        "# The weights willbe updated after the given batch size images flows.\n",
        "# Classmode the expected output\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (128, 128),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg1kF62cri6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         samples_per_epoch = 8000,\n",
        "                         nb_epoch = 25,\n",
        "                         validation_data = test_set,\n",
        "                         nb_val_samples = 2000)\n",
        "# Samples per epoch is the no of images we have in the training set\n",
        "# Epoc is repetation of the entire model again andagain.\n",
        "# Nb val samples is the no of images in the test set"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}